\title{Taxi Trajectory Prediction}
\author{
        Karl Krauth (z3416790)\\
        David McKinnon (z3421068)
}
\date{\today}

\documentclass[12pt]{article}

\begin{document}
\maketitle

\section{Introduction}
Taxis nowadays use electronic dispatch systems for scheduling pick-ups, but they do not usually enter their drop-off locations. Therefore, when a call comes for a taxi, it is difficult for dispatchers to know which taxi to contact. 

To improve the efficiency of electronic taxi dispatching systems it is important to be able to predict the final destination of a taxi while it is in service. Since there is often a taxi whose current ride will end near a requested pick up location from a new passenger, it would be useful to know approximately where each taxi is likely to end so that the system can identify the best taxi to assign to each new pickup request. This lowers the waiting time for new passengers and allows the taxi system to operate more efficiently.

This project occurs in the context of a Kaggle competition hosted by ECML/PKDD. The goal of this competition is to predict the destination of taxis travelling in Porto, Portugal given specific data about the current trip. To aid with this a dataset of around 1.7 million complete trips is provided.

\section{Features and Observations of the Data Set}
The spatial trajectory of an occupied taxi could provide some hints as to where it is going. Similarly, given the taxi id, it might be possible to predict its final destination based on the regularity of pre-hired services. In a significant number of taxi rides (approximately $25$\%), the taxi has been called through the taxi call-center, and the passenger's telephone id can be used to narrow the destination prediction based on historical ride data connected to their telephone id.

Initially, naive Bayesian conditions were graphed to find any potential connections in the data - frequency of taxi rides, given the time of day, or type of day, or taxi request type, or the average heading of the taxi from start to finish given the time/type of day/taxi request. These were plotted in a series of graphs shown below in Appendix 1. 
It was hoped that these could provide some hint as to the final destination - for example, taxis are most frequently called between the hours of X and Y. A 3D histogram was then created to check for a connection between time of day and average heading. This can be seen in Figure b) of Appendix 1. 

In all of these graphs no significant connections were found, except that the overwhelming majority of taxi trips took place not on or before public holidays - but this is obvious. 
The baseline approach was simply to classify all taxi rides as ending in downtown Porto - as the majority went here anyway, this proved effective. 
The approach in this project improved upon this and ended up using none of the connections hypothesised above. 

\section{Methods}
\subsection{Naive Bayes}


\subsection{Regression Trees and Boosting}
The second method that was attempted was the use of regression trees, both used by itself and augmented by AdaBoost. Before being able to train on the dataset we first went through a pre-processing step. The following features were modified as follows:
\begin{itemize}
  \item \textbf{ORIGIN\_CALL:} If set to a NULL value instead set it to 0.
  \item \textbf{ORIGIN\_STAND:} If set to a NULL value instead set it to 0.
  \item \textbf{CALL\_TYPE:} Remove this column since ORIGIN\_CALL and ORIGIN\_STAND give us the information we need about the CALL\_TYPE.
  \item \textbf{DAYTYPE:} Remove the DAYTYPE since they're all set to the same value.
  \item \textbf{MISSING\_DATA:} Remove any rows with missing data (only 10 datapoints have missing data)
  \item \textbf{POLYLINE:} Keep only the starting point, a randomly selected point in the middle and the end point (as the target value).
\end{itemize}
The idea behind the modification of POLYLINE is that we would like to transform a variable length vector into a fixed length vector, we also would like to modify polyline to only be a partial path since a complete path would not help with prediction.

After having modified the dataset we then train a regression tree on the generated training set. A maximum depth of 20 leads to good performance. We also train a regression tree used in conjunction with AdaBoost, however since 

\subsection{Frechet Distance and KNN}


\section{Results}

\section{Further Work}

\section{Conclusion}

\end{document}
